{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road** \n",
    "\n",
    "### Author: Aneeq Mahmood\n",
    "\n",
    "#### email: aneeq.sdc@gmail.com\n",
    "***\n",
    "The goal of the project is to first collect images from the front camera of the self driving car (SDC), and detect car driving lanes in it.  Once this has worked out for a set of images which are present in the 'test_images' folder, then the target will be to implement the same idea on the set of videos which are contained insude the 'test_videos' folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## packages used for image processing\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import operator \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Function used by program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def fit_line(xs,ys,a,b):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Collects the set of x and y coordinates of all points in lists 'xs' and 'ys' respectively.\n",
    "    A line fitting is done using these points using built in least square API which returns\n",
    "    a slope 'm' and intercept 'c'.  Paramters 'a' and 'b' are y coordinates of the\n",
    "    points between which a line will be drawn on top of video clip. The x coorindates\n",
    "    are obtained using 'a' and 'b' along with 'm' and 'c' and using\n",
    "    equation of a straight line\n",
    "\n",
    "    \"\"\"\n",
    "    # Chekcing against empty list, if empty return 0s\n",
    "    if  not (xs):\n",
    "        return 0,0,0,0\n",
    "    \n",
    "    # Preparing vectors for least square\n",
    "    z = np.vstack([xs, np.ones(len(xs))]).T\n",
    "    s = np.array(ys)\n",
    "\n",
    "    # Applying least square fitting on points\n",
    "    m, c = np.linalg.lstsq(z, np.array(ys))[0]   #Applying least squares method\n",
    "    \n",
    "    #Using slope and intercept plus y coordinates to get x-coordinates\n",
    "    x1 = int(a/m - c/m)              \n",
    "    x2 = int(b/m - c/m)\n",
    "    \n",
    "    return x1,a,x2,b\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=10):\n",
    "    \"\"\"\n",
    " \n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    " \n",
    "    \"\"\"\n",
    "    \n",
    "    yFinal = 540\n",
    "    yIni = 350\n",
    "    xPlus = []\n",
    "    yPlus = []\n",
    "    xMinus = []\n",
    "    yMinus= []\n",
    "    slope_range = 0.2\n",
    "    for line in lines:\n",
    "        \n",
    "        for x1,y1,x2,y2 in line:\n",
    "            \n",
    "            # check slope   \n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            \n",
    "            # Collect all points with + ve slope\n",
    "            if slope > slope_range:\n",
    "                xPlus.append(x1)\n",
    "                xPlus.append(x2)\n",
    "                yPlus.append(y1)\n",
    "                yPlus.append(y2)\n",
    "                \n",
    "            # Collect all points with - ve slope\n",
    "            elif slope < -slope_range:\n",
    "               \n",
    "                xMinus.append(x1)\n",
    "                xMinus.append(x2)\n",
    "                yMinus.append(y1)\n",
    "                yMinus.append(y2)\n",
    "            # If out of range, lists defined in beginning of this function will be empty  \n",
    "            else:\n",
    "                continue\n",
    "#            cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)\n",
    "\n",
    "\n",
    "    x1,y1,x2,y2 = fit_line(xPlus,yPlus, yIni,yFinal)\n",
    "    cv2.line(img,(x1,y1),(x2,y2),color, thickness)  \n",
    "    x1,y1,x2,y2 = fit_line(xMinus,yMinus, yIni,yFinal)\n",
    "    cv2.line(img,(x1,y1),(x2,y2),color,thickness)  \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane finding Pipeline function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def process_image(img) :\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Function takes an image as input, detect lanes inside and draws outputs\n",
    "    \n",
    "    \"\"\"\n",
    "#    Take the image and convert to greyscale\n",
    "    gray = grayscale(img)\n",
    "    \n",
    "    kernel_size = 7\n",
    "        \n",
    "    blur_gray = gaussian_blur(gray,kernel_size)\n",
    "    \n",
    "    # Parameters for canny edge detection\n",
    "    threshVal = 45\n",
    "    low_threshold = threshVal\n",
    "    high_threshold = threshVal*3\n",
    "    \n",
    "    # Applying canny on the greyed image\n",
    "    edges = canny(blur_gray, low_threshold, high_threshold)\n",
    "#    plt.figure()\n",
    "#    plt.imshow(edges)\n",
    "    \n",
    "    \n",
    "    # Masking out our area of interest \n",
    "    mask = np.zeros_like(edges)   \n",
    "    ignore_mask_color = 255 \n",
    "    imshape = img.shape\n",
    "    # Define four sided polygon, whose upper two vertices are chosen with hit and trial\n",
    "    # Lower vertices stretch down to image border\n",
    " \n",
    "    vertices = np.array([[(0,imshape[0]),(400, 350), (550, 350), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest (edges, vertices)\n",
    "#    plt.figure()\n",
    "#    plt.imshow(masked_edges)\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    #  Hough transform parameters\n",
    "    rho = 1# distance resolution in pixels of the Hough gridl\n",
    "    theta = 1*np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 20    # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 30 #minimum number of pixels making up a line\n",
    "    max_line_gap = 60    # maximum gap in pixels between connectable line segments\n",
    "    final_lines = np.copy(img)*0 # creating a blank to draw lines on\n",
    "    \n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"final _lines\" is an array containing endpoints of detected line segments\n",
    "    #lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]),\n",
    "    #                           min_line_length, max_line_gap)\n",
    "    final_lines = hough_lines(masked_edges, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "    # Create a \"color\" binary image to combine with line image\n",
    "    color_edges = np.dstack((img[:,:,0], img[:,:,1], img[:,:,2])) \n",
    "   \n",
    "    # Draw the lines on the edge image\n",
    "#  lines_edges = cv2.addWeighted(color_edges, 0.8, line_image, 1, 0) \n",
    "    final = weighted_img(final_lines, color_edges )\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the pipeline with still images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import os \n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "\n",
    "folder_name = 'test_images/'\n",
    "folder_name_res = 'test_images_results/'\n",
    "t_images =os.listdir(folder_name)\n",
    "\n",
    "for d in range(len(t_images)):\n",
    "\n",
    "    img = mpimg.imread(folder_name+t_images[d])    # original image\n",
    "    \n",
    "    pimg = process_image(img)                       # processed image\n",
    "    \n",
    "    #print (folder_name_res + 'processed_'+ t_images[d])\n",
    "    mpimg.imsave( folder_name_res + 'processed_'+ t_images[d],pimg)\n",
    "    \n",
    "    \n",
    "# Only plotting the last image\n",
    "plt.imshow(pimg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Videos \n",
    "\n",
    "### White Right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "\n",
    "clip2 = VideoFileClip('test_videos/solidWhiteRight.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Videos \n",
    "\n",
    "### Yellow Left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
